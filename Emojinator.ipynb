{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_x, image_y = 50, 50\\n\\ncap = cv2.VideoCapture(0)\\nfbag = cv2.createBackgroundSubtractorMOG2()\\n\\ndef create_folder(folder_name):\\n    if not os.path.exists(folder_name):\\n        os.mkdir(folder_name)\\n\\ndef main(g_id):\\n    total_pics = 1200\\n    cap = cv2.VideoCapture(0)\\n    x, y, w, h = 300, 50, 350, 350\\n\\n    create_folder(\"gestures/\" + str(g_id))\\n    pic_no = 0\\n    flag_start_capturing = False\\n    frames = 0\\n\\n    while True:\\n        ret, frame = cap.read()\\n        frame = cv2.flip(frame, 1)\\n        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\\n\\n        mask2 = cv2.inRange(hsv, np.array([2, 50, 60]), np.array([25, 150, 255]))\\n        res = cv2.bitwise_and(frame, frame, mask=mask2)\\n        gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\\n        median = cv2.GaussianBlur(gray, (5, 5), 0)\\n\\n        kernel_square = np.ones((5, 5), np.uint8)\\n        dilation = cv2.dilate(median, kernel_square, iterations=2)\\n        opening=cv2.morphologyEx(dilation,cv2.MORPH_CLOSE,kernel_square)\\n\\n        ret, thresh = cv2.threshold(opening, 30, 255, cv2.THRESH_BINARY)\\n        thresh = thresh[y:y + h, x:x + w]\\n        contours = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\\n\\n        if len(contours) > 0:\\n            contour = max(contours, key=cv2.contourArea)\\n            if cv2.contourArea(contour) > 10000 and frames > 50:\\n                x1, y1, w1, h1 = cv2.boundingRect(contour)\\n                pic_no += 1\\n                save_img = thresh[y1:y1 + h1, x1:x1 + w1]\\n                if w1 > h1:\\n                    save_img = cv2.copyMakeBorder(save_img, int((w1 - h1) / 2), int((w1 - h1) / 2), 0, 0,\\n                                                  cv2.BORDER_CONSTANT, (0, 0, 0))\\n                elif h1 > w1:\\n                    save_img = cv2.copyMakeBorder(save_img, 0, 0, int((h1 - w1) / 2), int((h1 - w1) / 2),\\n                                                  cv2.BORDER_CONSTANT, (0, 0, 0))\\n                save_img = cv2.resize(save_img, (image_x, image_y))\\n                cv2.putText(frame, \"Capturing...\", (30, 60), cv2.FONT_HERSHEY_TRIPLEX, 2, (127, 255, 255))\\n                cv2.imwrite(\"gestures/\" + str(g_id) + \"/\" + str(pic_no) + \".jpg\", save_img)\\n\\n        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\\n        cv2.putText(frame, str(pic_no), (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (127, 127, 255))\\n        cv2.imshow(\"Capturing gesture\", frame)\\n        cv2.imshow(\"thresh\", thresh)\\n        keypress = cv2.waitKey(1)\\n        if keypress == ord(\\'c\\'):\\n            if flag_start_capturing == False:\\n                flag_start_capturing = True\\n            else:\\n                flag_start_capturing = False\\n                frames = 0\\n        if flag_start_capturing == True:\\n            frames += 1\\n        if pic_no == total_pics:\\n            break\\n\\n\\ng_id = input(\"Enter gesture number: \")\\nmain(g_id)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\"\"\"image_x, image_y = 50, 50\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "fbag = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "\n",
    "def main(g_id):\n",
    "    total_pics = 1200\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    x, y, w, h = 300, 50, 350, 350\n",
    "\n",
    "    create_folder(\"gestures/\" + str(g_id))\n",
    "    pic_no = 0\n",
    "    flag_start_capturing = False\n",
    "    frames = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        mask2 = cv2.inRange(hsv, np.array([2, 50, 60]), np.array([25, 150, 255]))\n",
    "        res = cv2.bitwise_and(frame, frame, mask=mask2)\n",
    "        gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "        median = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        kernel_square = np.ones((5, 5), np.uint8)\n",
    "        dilation = cv2.dilate(median, kernel_square, iterations=2)\n",
    "        opening=cv2.morphologyEx(dilation,cv2.MORPH_CLOSE,kernel_square)\n",
    "\n",
    "        ret, thresh = cv2.threshold(opening, 30, 255, cv2.THRESH_BINARY)\n",
    "        thresh = thresh[y:y + h, x:x + w]\n",
    "        contours = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "\n",
    "        if len(contours) > 0:\n",
    "            contour = max(contours, key=cv2.contourArea)\n",
    "            if cv2.contourArea(contour) > 10000 and frames > 50:\n",
    "                x1, y1, w1, h1 = cv2.boundingRect(contour)\n",
    "                pic_no += 1\n",
    "                save_img = thresh[y1:y1 + h1, x1:x1 + w1]\n",
    "                if w1 > h1:\n",
    "                    save_img = cv2.copyMakeBorder(save_img, int((w1 - h1) / 2), int((w1 - h1) / 2), 0, 0,\n",
    "                                                  cv2.BORDER_CONSTANT, (0, 0, 0))\n",
    "                elif h1 > w1:\n",
    "                    save_img = cv2.copyMakeBorder(save_img, 0, 0, int((h1 - w1) / 2), int((h1 - w1) / 2),\n",
    "                                                  cv2.BORDER_CONSTANT, (0, 0, 0))\n",
    "                save_img = cv2.resize(save_img, (image_x, image_y))\n",
    "                cv2.putText(frame, \"Capturing...\", (30, 60), cv2.FONT_HERSHEY_TRIPLEX, 2, (127, 255, 255))\n",
    "                cv2.imwrite(\"gestures/\" + str(g_id) + \"/\" + str(pic_no) + \".jpg\", save_img)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, str(pic_no), (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (127, 127, 255))\n",
    "        cv2.imshow(\"Capturing gesture\", frame)\n",
    "        cv2.imshow(\"thresh\", thresh)\n",
    "        keypress = cv2.waitKey(1)\n",
    "        if keypress == ord('c'):\n",
    "            if flag_start_capturing == False:\n",
    "                flag_start_capturing = True\n",
    "            else:\n",
    "                flag_start_capturing = False\n",
    "                frames = 0\n",
    "        if flag_start_capturing == True:\n",
    "            frames += 1\n",
    "        if pic_no == total_pics:\n",
    "            break\n",
    "\n",
    "\n",
    "g_id = input(\"Enter gesture number: \")\n",
    "main(g_id)\"\"\"#creating your own gesture dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.jpg\n",
      "10.jpg\n",
      "100.jpg\n",
      "1000.jpg\n",
      "1001.jpg\n",
      "1002.jpg\n",
      "1003.jpg\n",
      "1004.jpg\n",
      "1005.jpg\n",
      "1006.jpg\n",
      "1007.jpg\n",
      "1008.jpg\n",
      "1009.jpg\n",
      "101.jpg\n",
      "1010.jpg\n",
      "1011.jpg\n",
      "1012.jpg\n",
      "1013.jpg\n",
      "1014.jpg\n",
      "1015.jpg\n",
      "1016.jpg\n",
      "1017.jpg\n",
      "1018.jpg\n",
      "1019.jpg\n",
      "102.jpg\n",
      "1020.jpg\n",
      "1021.jpg\n",
      "1022.jpg\n",
      "1023.jpg\n",
      "1024.jpg\n",
      "1025.jpg\n",
      "1026.jpg\n",
      "1027.jpg\n",
      "1028.jpg\n",
      "1029.jpg\n",
      "103.jpg\n",
      "1030.jpg\n",
      "1031.jpg\n",
      "1032.jpg\n",
      "1033.jpg\n",
      "1034.jpg\n",
      "1035.jpg\n",
      "1036.jpg\n",
      "1037.jpg\n",
      "1038.jpg\n",
      "1039.jpg\n",
      "104.jpg\n",
      "1040.jpg\n",
      "1041.jpg\n",
      "1042.jpg\n",
      "1043.jpg\n",
      "1044.jpg\n",
      "1045.jpg\n",
      "1046.jpg\n",
      "1047.jpg\n",
      "1048.jpg\n",
      "1049.jpg\n",
      "105.jpg\n",
      "1050.jpg\n",
      "1051.jpg\n",
      "1052.jpg\n",
      "1053.jpg\n",
      "1054.jpg\n",
      "1055.jpg\n",
      "1056.jpg\n",
      "1057.jpg\n",
      "1058.jpg\n",
      "1059.jpg\n",
      "106.jpg\n",
      "1060.jpg\n",
      "1061.jpg\n",
      "1062.jpg\n",
      "1063.jpg\n",
      "1064.jpg\n",
      "1065.jpg\n",
      "1066.jpg\n",
      "1067.jpg\n",
      "1068.jpg\n",
      "1069.jpg\n",
      "107.jpg\n",
      "1070.jpg\n",
      "1071.jpg\n",
      "1072.jpg\n",
      "1073.jpg\n",
      "1074.jpg\n",
      "1075.jpg\n",
      "1076.jpg\n",
      "1077.jpg\n",
      "1078.jpg\n",
      "1079.jpg\n",
      "108.jpg\n",
      "1080.jpg\n",
      "1081.jpg\n",
      "1082.jpg\n",
      "1083.jpg\n",
      "1084.jpg\n",
      "1085.jpg\n",
      "1086.jpg\n",
      "1087.jpg\n",
      "1088.jpg\n",
      "1089.jpg\n",
      "109.jpg\n",
      "1090.jpg\n",
      "1091.jpg\n",
      "1092.jpg\n",
      "1093.jpg\n",
      "1094.jpg\n",
      "1095.jpg\n",
      "1096.jpg\n",
      "1097.jpg\n",
      "1098.jpg\n",
      "1099.jpg\n",
      "11.jpg\n",
      "110.jpg\n",
      "1100.jpg\n",
      "1101.jpg\n",
      "1102.jpg\n",
      "1103.jpg\n",
      "1104.jpg\n",
      "1105.jpg\n",
      "1106.jpg\n",
      "1107.jpg\n",
      "1108.jpg\n",
      "1109.jpg\n",
      "111.jpg\n",
      "1110.jpg\n",
      "1111.jpg\n",
      "1112.jpg\n",
      "1113.jpg\n",
      "1114.jpg\n",
      "1115.jpg\n",
      "1116.jpg\n",
      "1117.jpg\n",
      "1118.jpg\n",
      "1119.jpg\n",
      "112.jpg\n",
      "1120.jpg\n",
      "1121.jpg\n",
      "1122.jpg\n",
      "1123.jpg\n",
      "1124.jpg\n",
      "1125.jpg\n",
      "1126.jpg\n",
      "1127.jpg\n",
      "1128.jpg\n",
      "1129.jpg\n",
      "113.jpg\n",
      "1130.jpg\n",
      "1131.jpg\n",
      "1132.jpg\n",
      "1133.jpg\n",
      "1134.jpg\n",
      "1135.jpg\n",
      "1136.jpg\n",
      "1137.jpg\n",
      "1138.jpg\n",
      "1139.jpg\n",
      "114.jpg\n",
      "1140.jpg\n",
      "1141.jpg\n",
      "1142.jpg\n",
      "1143.jpg\n",
      "1144.jpg\n",
      "1145.jpg\n",
      "1146.jpg\n",
      "1147.jpg\n",
      "1148.jpg\n",
      "1149.jpg\n",
      "115.jpg\n",
      "1150.jpg\n",
      "1151.jpg\n",
      "1152.jpg\n",
      "1153.jpg\n",
      "1154.jpg\n",
      "1155.jpg\n",
      "1156.jpg\n",
      "1157.jpg\n",
      "1158.jpg\n",
      "1159.jpg\n",
      "116.jpg\n",
      "1160.jpg\n",
      "1161.jpg\n",
      "1162.jpg\n",
      "1163.jpg\n",
      "1164.jpg\n",
      "1165.jpg\n",
      "1166.jpg\n",
      "1167.jpg\n",
      "1168.jpg\n",
      "1169.jpg\n",
      "117.jpg\n",
      "1170.jpg\n",
      "1171.jpg\n",
      "1172.jpg\n",
      "1173.jpg\n",
      "1174.jpg\n",
      "1175.jpg\n",
      "1176.jpg\n",
      "1177.jpg\n",
      "1178.jpg\n",
      "1179.jpg\n",
      "118.jpg\n",
      "1180.jpg\n",
      "1181.jpg\n",
      "1182.jpg\n",
      "1183.jpg\n",
      "1184.jpg\n",
      "1185.jpg\n"
     ]
    }
   ],
   "source": [
    "#convert dataset into csv file\n",
    "#1st approach\n",
    "#from scipy.misc import imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "root = './gestures' # or ‘./test’ depending on for which the CSV is being created\n",
    "\n",
    "# go through each directory in the root folder given above\n",
    "for directory, subdirectories, files in os.walk(root):\n",
    "# go through each file in that directory\n",
    "    for file in files:\n",
    "    # read the image file and extract its pixels\n",
    "        print(file)\n",
    "        im =cv2.imread(os.path.join(directory,file))\n",
    "        value = im.flatten()\n",
    "# I renamed the folders containing digits to the contained digit itself. For example, digit_0 folder was renamed to 0.\n",
    "# so taking the 9th value of the folder gave the digit (i.e. \"./train/8\" ==> 9th value is 8), which was inserted into the first column of the dataset.\n",
    "        value = np.hstack((directory[11:],value))\n",
    "        df = pd.DataFrame(value).T\n",
    "        df = df.sample(frac=1) # shuffle the dataset\n",
    "        with open('train_foo.csv', 'a') as dataset:\n",
    "            df.to_csv(dataset, header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd approach using pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 12000\n",
      "number of test examples = 1199\n",
      "X_train shape: (12000, 2500)\n",
      "Y_train shape: (1, 12000)\n",
      "X_test shape: (1199, 2500)\n",
      "Y_test shape: (1, 1199)\n",
      "X_train shape: (12000, 50, 50, 1)\n",
      "X_test shape: (1199, 50, 50, 1)\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 41s 210ms/step - loss: 1.3211 - accuracy: 0.5760 - val_loss: 0.0064 - val_accuracy: 0.9975\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 40s 215ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 3.5962e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 39s 208ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 1.8875e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 43s 227ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 6.4288e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 42s 224ms/step - loss: 6.1253e-04 - accuracy: 1.0000 - val_loss: 2.5391e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 64s 341ms/step - loss: 3.2430e-04 - accuracy: 1.0000 - val_loss: 1.7163e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 59s 315ms/step - loss: 2.4220e-04 - accuracy: 1.0000 - val_loss: 1.2962e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 60s 322ms/step - loss: 2.4493e-04 - accuracy: 1.0000 - val_loss: 1.0379e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 63s 337ms/step - loss: 2.3776e-04 - accuracy: 1.0000 - val_loss: 8.8573e-06 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 61s 325ms/step - loss: 1.9380e-04 - accuracy: 1.0000 - val_loss: 5.7705e-06 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "CNN Error: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 12\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath = \"emojinator.h5\"\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint1]\n",
    "\n",
    "    return model, callbacks_list\n",
    "\n",
    "def main():\n",
    "    data = pd.read_csv(\"train_foo.csv\")\n",
    "    dataset = np.array(data)\n",
    "    np.random.shuffle(dataset)\n",
    "    X = dataset\n",
    "    Y = dataset\n",
    "    X = X[:, 1:2501]\n",
    "    Y = Y[:, 0]\n",
    "\n",
    "    X_train = X[0:12000, :]\n",
    "    X_train = X_train / 255.\n",
    "    X_test = X[12000:13201, :]\n",
    "    X_test = X_test / 255.\n",
    "\n",
    "    # Reshape\n",
    "    Y = Y.reshape(Y.shape[0], 1)\n",
    "    Y_train = Y[0:12000, :]\n",
    "    Y_train = Y_train.T\n",
    "    Y_test = Y[12000:13201, :]\n",
    "    Y_test = Y_test.T\n",
    "\n",
    "    print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "    print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "    print(\"X_train shape: \" + str(X_train.shape))\n",
    "    print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "    print(\"X_test shape: \" + str(X_test.shape))\n",
    "    print(\"Y_test shape: \" + str(Y_test.shape))\n",
    "    image_x = 50\n",
    "    image_y = 50\n",
    "\n",
    "    train_y = np_utils.to_categorical(Y_train)\n",
    "    test_y = np_utils.to_categorical(Y_test)\n",
    "    train_y = train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "    test_y = test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "    X_train = X_train.reshape(X_train.shape[0], 50, 50, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 50, 50, 1)\n",
    "    print(\"X_train shape: \" + str(X_train.shape))\n",
    "    print(\"X_test shape: \" + str(X_test.shape))\n",
    "\n",
    "    model, callbacks_list = keras_model(image_x, image_y)\n",
    "    model.fit(X_train, train_y, validation_data=(X_test, test_y), epochs=10, batch_size=64,\n",
    "              callbacks=callbacks_list)\n",
    "    scores = model.evaluate(X_test, test_y, verbose=0)\n",
    "    print(\"CNN Error: %.2f%%\" % (100 - scores[1] * 100))\n",
    "\n",
    "    model.save('emojinator.h5')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "5 0.96868783\n",
      "5 0.96868783\n",
      "1 0.96199566\n",
      "9 0.9999454\n",
      "9 1.0\n",
      "9 0.99999917\n",
      "9 0.85574025\n",
      "9 0.99998724\n",
      "9 0.99998724\n",
      "1 0.66170067\n",
      "3 0.84384626\n",
      "1 0.66566485\n",
      "1 0.66566485\n",
      "1 0.9989766\n",
      "3 0.930394\n",
      "9 0.9998735\n",
      "9 0.9998735\n",
      "3 0.6166548\n",
      "11 0.98127055\n",
      "5 0.99974054\n",
      "5 0.9993411\n",
      "5 0.9993512\n",
      "5 0.99997985\n",
      "5 0.9999651\n",
      "5 0.9999989\n",
      "5 0.9998673\n",
      "5 0.9999249\n",
      "5 0.9998621\n",
      "5 0.9999995\n",
      "5 0.9999517\n",
      "5 0.9999933\n",
      "5 0.9999757\n",
      "5 0.999998\n",
      "5 0.9999888\n",
      "8 0.466381\n",
      "5 0.9999987\n",
      "3 0.98530734\n",
      "8 0.71243507\n",
      "5 0.78214747\n",
      "3 0.99435437\n",
      "3 0.9788983\n",
      "3 0.9249686\n",
      "3 0.9668487\n",
      "3 0.98135376\n",
      "3 0.9954464\n",
      "3 0.92148787\n",
      "3 0.9972345\n",
      "3 0.95222735\n",
      "7 0.64909536\n",
      "7 0.999969\n",
      "11 0.61340094\n",
      "7 0.99520725\n",
      "4 0.85517037\n",
      "3 0.89551216\n",
      "4 0.80970526\n",
      "3 0.8329978\n",
      "7 0.99555546\n",
      "7 0.96411574\n",
      "7 0.6640663\n",
      "7 0.62892514\n",
      "3 0.9747122\n",
      "3 0.6662827\n",
      "3 0.9932637\n",
      "3 0.98568195\n",
      "5 0.6235291\n",
      "5 0.8269538\n",
      "5 0.99448216\n",
      "5 0.9551488\n",
      "3 0.94677323\n",
      "3 0.9886026\n",
      "2 0.87394816\n",
      "3 0.932476\n",
      "5 0.9955836\n",
      "5 0.9999895\n",
      "5 0.99999976\n",
      "5 0.9999622\n",
      "5 0.99995685\n",
      "5 0.99997675\n",
      "5 0.99998343\n",
      "5 0.9998716\n",
      "5 0.9999925\n",
      "1 0.9343198\n",
      "11 0.8269561\n",
      "11 0.9996687\n",
      "5 0.7869014\n",
      "7 0.948147\n",
      "7 0.89087737\n",
      "7 0.98206687\n",
      "7 0.99940073\n",
      "7 0.8740815\n",
      "7 0.9966366\n",
      "7 0.9609022\n",
      "7 0.99743503\n",
      "7 0.5476899\n",
      "7 0.71935064\n",
      "5 0.9964663\n",
      "5 0.99999833\n",
      "5 0.9996427\n",
      "5 0.9999825\n",
      "5 0.9999826\n",
      "5 0.9999678\n",
      "5 0.99997103\n",
      "5 0.9999937\n",
      "5 0.9999968\n",
      "5 0.9999945\n",
      "5 0.99999225\n",
      "5 0.99994206\n",
      "5 0.9999714\n",
      "1 0.7002783\n",
      "5 0.96573246\n",
      "8 0.59085447\n",
      "2 0.39681196\n",
      "5 0.42182723\n",
      "5 0.7748392\n",
      "5 0.67400986\n",
      "3 0.4093585\n",
      "3 0.5335583\n",
      "1 0.956643\n",
      "1 0.9487005\n",
      "8 0.5629281\n",
      "11 0.642396\n",
      "5 0.9634529\n",
      "5 0.9681658\n",
      "5 0.9834394\n",
      "5 0.9960849\n",
      "5 0.99351853\n",
      "5 0.98758686\n",
      "5 0.99327236\n",
      "1 0.95519334\n",
      "5 0.5509641\n",
      "1 0.98542213\n",
      "1 0.91074944\n",
      "5 0.7160956\n",
      "5 0.52576256\n",
      "5 0.7527704\n",
      "1 0.7850558\n",
      "1 0.5991632\n",
      "5 0.9188538\n",
      "1 0.9632448\n",
      "5 0.5725814\n",
      "5 0.976227\n",
      "5 0.5417788\n",
      "5 0.9260881\n",
      "1 0.5453376\n",
      "1 0.6641105\n",
      "5 0.9714462\n",
      "5 0.62465656\n",
      "5 0.9899081\n",
      "3 0.7308957\n",
      "5 0.4728714\n",
      "5 0.79112166\n",
      "11 0.92954665\n",
      "1 0.6940475\n",
      "11 0.825123\n",
      "5 0.8349046\n",
      "11 0.88846165\n",
      "5 0.495223\n",
      "5 0.8166748\n",
      "5 0.9788544\n",
      "11 0.8231441\n",
      "5 0.9876588\n",
      "5 0.99766684\n",
      "5 0.9903689\n",
      "5 0.99931085\n",
      "5 0.916081\n",
      "5 0.99925894\n",
      "5 0.9999565\n",
      "4 0.8259944\n",
      "11 0.9229542\n",
      "8 0.5697502\n",
      "5 0.99283713\n",
      "5 0.93664044\n",
      "5 0.92726535\n",
      "5 0.96990496\n",
      "5 0.990948\n",
      "5 0.99918693\n",
      "5 0.99559903\n",
      "5 0.9939121\n",
      "5 0.9805468\n",
      "1 0.6027213\n",
      "5 0.6266484\n",
      "11 0.65459824\n",
      "11 0.7442792\n",
      "5 0.53865004\n",
      "11 0.7099322\n",
      "5 0.9903867\n",
      "5 0.9927059\n",
      "5 0.8901179\n",
      "11 0.9437734\n",
      "5 0.6375706\n",
      "1 0.31256685\n",
      "5 0.9978719\n",
      "5 0.97686756\n",
      "5 0.9977416\n",
      "5 0.9989716\n",
      "2 0.5278643\n",
      "5 0.7702087\n",
      "5 0.74970543\n",
      "11 0.6431362\n",
      "1 0.5628369\n",
      "7 0.6807654\n",
      "1 0.8871672\n",
      "1 0.9960627\n",
      "5 0.9639203\n",
      "1 0.9787309\n",
      "1 0.9949809\n",
      "11 0.42152438\n",
      "11 0.65180814\n",
      "11 0.7786235\n",
      "11 0.6440906\n",
      "3 0.514719\n",
      "11 0.7502294\n",
      "11 0.6902186\n",
      "11 0.504004\n",
      "11 0.93202114\n",
      "3 0.48739433\n",
      "5 0.97780734\n",
      "8 0.44118065\n",
      "8 0.68757373\n",
      "8 0.68757373\n",
      "5 0.78236985\n",
      "5 0.9587592\n",
      "8 0.78609306\n",
      "9 0.5830202\n",
      "8 0.4898441\n",
      "5 0.85407794\n",
      "5 0.85407794\n",
      "9 0.9983145\n",
      "9 0.9983145\n",
      "9 0.53161174\n",
      "1 0.80410606\n",
      "1 0.81928295\n",
      "1 0.81928295\n",
      "9 0.9974401\n",
      "1 0.99976414\n",
      "5 0.6595632\n",
      "5 0.6595632\n",
      "9 0.5957854\n",
      "9 0.99678123\n",
      "9 0.99678123\n",
      "1 0.98653895\n",
      "9 0.9995467\n",
      "5 0.9843258\n",
      "5 0.9843258\n",
      "3 0.5404883\n",
      "3 0.84522456\n",
      "3 0.5808741\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model = load_model('emojinator.h5')\n",
    "\n",
    "def main():\n",
    "    emojis = get_emojis()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    x, y, w, h = 300, 50, 350, 350\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        img = cv2.flip(img, 1)\n",
    "        if ret:\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            mask2 = cv2.inRange(hsv, np.array([2, 50, 60]), np.array([25, 150, 255]))\n",
    "            res = cv2.bitwise_and(img, img, mask=mask2)\n",
    "            gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "            median = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "            kernel_square = np.ones((5, 5), np.uint8)\n",
    "            dilation = cv2.dilate(median, kernel_square, iterations=2)\n",
    "            opening = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel_square)\n",
    "            ret, thresh = cv2.threshold(opening, 30, 255, cv2.THRESH_BINARY)\n",
    "            thresh = thresh[y:y + h, x:x + w]\n",
    "            contours = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[0]\n",
    "            if len(contours) > 0:\n",
    "                contour = max(contours, key=cv2.contourArea)\n",
    "                if cv2.contourArea(contour) > 2500:\n",
    "                    x, y, w1, h1 = cv2.boundingRect(contour)\n",
    "                    newImage = thresh[y:y + h1, x:x + w1]\n",
    "                    newImage = cv2.resize(newImage, (50, 50))\n",
    "                    pred_probab, pred_class = keras_predict(model, newImage)\n",
    "                    print(pred_class, pred_probab)\n",
    "                    img = overlay(img, emojis[pred_class], 400, 250, 90, 90)\n",
    "\n",
    "            x, y, w, h = 300, 50, 350, 350\n",
    "            cv2.imshow(\"Frame\", img)\n",
    "            cv2.imshow(\"Contours\", thresh)\n",
    "            if cv2.waitKey(27) & 0xFF==ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    cap.release() \n",
    "    cv2.destroyAllWindows()\n",
    "           \n",
    "\n",
    "def keras_predict(model, image):\n",
    "    processed = keras_process_image(image)\n",
    "    pred_probab = model.predict(processed)[0]\n",
    "    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "    return max(pred_probab), pred_class\n",
    "\n",
    "\n",
    "def keras_process_image(img):\n",
    "    image_x = 50\n",
    "    image_y = 50\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img\n",
    "\n",
    "def get_emojis():\n",
    "    emojis_folder = 'hand_emo/'\n",
    "    emojis = []\n",
    "    for emoji in range(len(os.listdir(emojis_folder))):\n",
    "        print(emoji)\n",
    "        emojis.append(cv2.imread(emojis_folder+str(emoji)+'.png', -1))\n",
    "    return emojis\n",
    "\n",
    "def overlay(image, emoji, x,y,w,h):\n",
    "    emoji = cv2.resize(emoji, (w, h))\n",
    "    try:\n",
    "        image[y:y+h, x:x+w] = blend_transparent(image[y:y+h, x:x+w], emoji)\n",
    "    except:\n",
    "        pass\n",
    "    return image\n",
    "\n",
    "def blend_transparent(face_img, overlay_t_img):\n",
    "    # Split out the transparency mask from the colour info\n",
    "    overlay_img = overlay_t_img[:,:,:3] # Grab the BRG planes\n",
    "    overlay_mask = overlay_t_img[:,:,3:]  # And the alpha plane\n",
    "\n",
    "    # Again calculate the inverse mask\n",
    "    background_mask = 255 - overlay_mask\n",
    "\n",
    "    # Turn the masks into three channel, so we can use them as weights\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert the images to floating point in range 0.0 - 1.0\n",
    "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "    # And finally just add them together, and rescale it back to an 8bit integer image\n",
    "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))\n",
    "\n",
    "keras_predict(model, np.zeros((50, 50, 1), dtype=np.uint8))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
